////
changes: ["Initial performance and inlining chapter"]
examples_compile: yes
keywords: ["performance", "inline", "vector"]
last_updated: 2025-11-06
last_verified: 2025-11-06
next_chapter: "40__profiling-optimization-hardening"
open_questions: []
previous_chapter: "38__zig-cli-deep-dive"
status: draft
xref_complete: true
////

= Performance & Inlining
:chapter-number: 39
:chapter-slug: performance-and-inlining
:creative-commons:
:copyright: zigbook
:doctype: book
:embedded:
:experimental:
:icons: font
:partnums:
:pygments-linenums-mode: inline
:pygments-style: manni
:safe-mode-level: 0
:sectanchors:
:sectids:
:sectlinks:
:source-highlighter: pygments
:sourcedir: example$chapters-data/code
:webfonts:
:xrefstyle: short
:zig-version: 0.15.2
:linkcss:
:stylesdir: styles
:stylesheet: zigbook.css

[[overview]]
== Overview

Our CLI survey set the stage for disciplined experimentation. xref:38__zig-cli-deep-dive.adoc[38] Now we focus on how Zig translates those command-line toggles into machine-level behavior. Semantic inlining, call modifiers, and explicit SIMD all give you levers to shape hot paths—provided you measure carefully and respect the compiler's defaults. link:https://ziglang.org/documentation/master/#inline-fn[#inline fn]

The next chapter formalizes that measurement loop by layering profiling and hardening workflows on top. xref:40__profiling-optimization-hardening.adoc[40]

[[learning-goals]]
== Learning Goals

* Force or forbid inlining when compile-time semantics must win over heuristics.
* Sample hot loops with `@call` and `std.time.Timer` to compare build modes.
* Use `@Vector` math as a bridge to portable SIMD before reaching for target-specific intrinsics.

link:https://ziglang.org/documentation/master/#call[#call], link:https://github.com/ziglang/zig/tree/master/lib/std/time/Timer.zig[Timer.zig], link:https://ziglang.org/documentation/master/#vectors[#vectors]

[[inline-semantics]]
== Semantic Inlining vs Optimizer Heuristics

Zig's `inline` keyword changes evaluation rules rather than hinting at the optimizer: compile-time known arguments become compile-time constants, allowing you to generate types or precompute values that ordinary calls would defer to runtime.

Inline functions restrict the compiler's freedom, so reach for them only when semantics matter—propagating `comptime` data, improving debugging, or satisfying real benchmarks.

=== Understanding Optimization Modes

Before exploring inlining behavior, it's important to understand the optimization modes that affect how the compiler treats your code. The following diagram shows the optimization configuration:

[mermaid]
....
graph TB
    subgraph "Optimization"
        OPTIMIZE["Optimization Settings"]
        OPTIMIZE --> OPTMODE["optimize_mode: OptimizeMode<br/>Debug, ReleaseSafe, ReleaseFast, ReleaseSmall"]
        OPTIMIZE --> LTO["lto: bool<br/>Link Time Optimization"]
    end
....

Zig provides four distinct optimization modes, each making different tradeoffs between safety, speed, and binary size. **Debug** mode disables optimizations and keeps full runtime safety checks, making it ideal for development and debugging. The compiler preserves stack frames, emits symbol information, and never inlines functions unless semantically required. **ReleaseSafe** enables optimizations while retaining all safety checks (bounds checking, integer overflow detection, etc.), balancing performance with error detection. **ReleaseFast** maximizes speed by disabling runtime safety checks and enabling aggressive optimizations including heuristic inlining. This is the mode used in the benchmarks throughout this chapter. **ReleaseSmall** prioritizes binary size over speed, often disabling inlining entirely to reduce code duplication.

Additionally, **Link Time Optimization (LTO)** can be enabled independently via `-flto`, allowing the linker to perform whole-program optimization across compilation units. When benchmarking inlining behavior, these modes dramatically affect results: `inline` functions behave identically across modes (semantic guarantee), but heuristic inlining in ReleaseFast may inline functions that Debug or ReleaseSmall would leave as calls. The chapter's examples use `-OReleaseFast` to showcase optimizer behavior, but you should test across modes to understand the full performance spectrum.

[[inline-fibonacci]]
=== Example: compile-time math with inline functions

`inline` recursion lets us bake small computations into the binary while leaving a fallback runtime path for larger inputs. The `@call` builtin provides a direct handle to evaluate call sites at compile time when arguments are available.

[source,zig]
----
include::{sourcedir}/39__performance-and-inlining/01_inline_semantics.zig[]
----

.Run
[source,shell]
----
$ zig test 01_inline_semantics.zig
----

.Output
[source,shell]
----
All 3 tests passed.
----

TIP: The `.compile_time` modifier fails if the callee touches runtime-only state. Wrap such experiments in `comptime` blocks first, then add runtime tests so release builds remain covered.

[[call-modifiers]]
== Directing Calls for Measurement

Zig 0.15.2's self-hosted backends reward accurate microbenchmarks. They can deliver dramatic speedups when paired with the new threaded code generation pipeline. link:https://ziglang.org/download/0.15.1/release-notes.html#threaded-codegen[v0.15.2]

Use `@call` modifiers to compare inline, default, and never-inline dispatches without refactoring your call sites.

[[call-benchmark]]
=== Example: comparing call modifiers under ReleaseFast

This benchmark pins the optimizer (`-OReleaseFast`) while we toggle call modifiers. Every variant produces the same result, but the timing highlights how `never_inline` can balloon hot loops when function call overhead dominates.

[source,zig]
----
include::{sourcedir}/39__performance-and-inlining/03_call_benchmark.zig[]
----

.Run
[source,shell]
----
$ zig run 03_call_benchmark.zig -OReleaseFast
----

.Output
[source,shell]
----
optimize-mode=ReleaseFast iterations=5000000
auto call   : 161394 ns
always_inline: 151745 ns
never_inline : 2116797 ns
----

NOTE: Performing the same run under `-OReleaseSafe` makes the gap larger because additional safety checks amplify the per-call overhead. link:https://ziglang.org/download/0.15.1/release-notes.html#x86-backend[v0.15.2] Use `zig run --time-report` from the previous chapter when you want compiler-side attribution for slow code paths. xref:38__zig-cli-deep-dive.adoc#cli-webui[38]

[[vectorization]]
== Portable Vectorization with @Vector

When the compiler cannot infer SIMD usage on its own, `@Vector` types offer a portable shim that respects safety checks and fallback scalar execution. Paired with `@reduce`, you can express horizontal reductions without writing target-specific intrinsics. link:https://ziglang.org/documentation/master/#reduce[#reduce]

[[vector-example]]
=== Example: SIMD-friendly dot product

The scalar and vectorized versions produce identical results. Profiling determines whether the extra vector plumbing pays off on your target.

[source,zig]
----
include::{sourcedir}/39__performance-and-inlining/02_vector_reduction.zig[]
----

.Run
[source,shell]
----
$ zig test 02_vector_reduction.zig
----

.Output
[source,shell]
----
All 1 tests passed.
----

TIP: Once you start mixing vectors and scalars, use `@splat` to lift constants and avoid the implicit casts forbidden by the vector rules.

[[notes-caveats]]
== Notes & Caveats

* Inline recursion counts against the compile-time branch quota. Raise it with `@setEvalBranchQuota` only when measurements prove the extra compile-time work is worthwhile. link:https://ziglang.org/documentation/master/#setevalbranchquota[#setevalbranchquota]
* Switching between `@call(.always_inline, ...)` and the `inline` keyword matters: the former applies to a single site, whereas `inline` modifies the callee definition and every future call.
* Vector lengths other than powers of two may fall back to scalar loops on some targets. Capture the generated assembly with `zig build-exe -femit-asm` before banking on a win.

=== Code Generation Features Affecting Performance

Beyond optimization modes, several code generation features affect runtime performance and debuggability. Understanding these flags helps you reason about performance tradeoffs:

[mermaid]
....
graph TB
    subgraph "Code Generation Features"
        Features["Feature Flags"]

        Features --> UnwindTables["unwind_tables: bool"]
        Features --> StackProtector["stack_protector: bool"]
        Features --> StackCheck["stack_check: bool"]
        Features --> RedZone["red_zone: ?bool"]
        Features --> OmitFramePointer["omit_frame_pointer: bool"]
        Features --> Valgrind["valgrind: bool"]
        Features --> SingleThreaded["single_threaded: bool"]

        UnwindTables --> EHFrame["Generate .eh_frame<br/>for exception handling"]

        StackProtector --> CanaryCheck["Stack canary checks<br/>buffer overflow detection"]

        StackCheck --> ProbeStack["Stack probing<br/>prevents overflow"]

        RedZone --> RedZoneSpace["Red zone optimization<br/>(x86_64, AArch64)"]

        OmitFramePointer --> NoFP["Omit frame pointer<br/>for performance"]

        Valgrind --> ValgrindSupport["Valgrind client requests<br/>for memory debugging"]

        SingleThreaded --> NoThreading["Assume single-threaded<br/>enable optimizations"]
    end
....

The **omit_frame_pointer** flag is particularly relevant for performance work: when enabled (typical in ReleaseFast), the compiler frees the frame pointer register (RBP on x86_64, FP on ARM) for general use, improving register allocation and enabling more aggressive optimizations. However, this makes stack unwinding harder. Debuggers and profilers may produce incomplete or missing stack traces.

The **red_zone** optimization (x86_64 and AArch64 only) allows functions to use 128 bytes below the stack pointer without adjusting RSP, reducing prologue/epilogue overhead in leaf functions. **Stack protection** adds canary checks to detect buffer overflows but adds runtime cost. This is why ReleaseFast disables it. **Stack checking** instruments functions to probe the stack and prevent overflow, useful for deep recursion but costly. **Unwind tables** generate `.eh_frame` sections for exception handling and debugger stack walks. Debug mode always includes them; release modes may omit them for size.

When the exercises suggest measuring allocator hot paths with `@call(.never_inline, ...)`, these flags explain why Debug mode shows better stack traces (frame pointers preserved) at the cost of slower execution (extra instructions, no register optimization). Performance-critical code should benchmark with ReleaseFast but validate correctness with Debug to catch issues the optimizer might hide.

[[exercises]]
== Exercises

* Add a `--mode` flag to the benchmark program so you can flip between Debug, ReleaseSafe, and ReleaseFast runs without editing the code. xref:38__zig-cli-deep-dive.adoc#cli-run-summary[38]
* Extend the dot-product example with a remainder loop that handles slices whose lengths are not multiples of four. Measure the crossover point where SIMD still wins.
* Experiment with `@call(.never_inline, ...)` on allocator hot paths from Chapter 10 to confirm whether improved stack traces in Debug are worth the runtime cost. xref:10__allocators-and-memory-management.adoc[10]

[[caveats-alternatives-edge-cases]]
== Alternatives & Edge Cases:

* Microbenchmarks that run inside `zig run` share the compilation cache. Warm the cache with a dummy run before comparing timings to avoid skew. link:ZIG_DEEP_WIKI.md#entry-points-and-command-structure[#entry points and command structure]
* The self-hosted x86 backend is fast but not perfect. Fall back to `-fllvm` if you notice miscompilations while exploring aggressive inline patterns.
* ReleaseSmall often disables inlining entirely to save size. When you need both tiny binaries and tuned hot paths, isolate the hot functions and call them from a ReleaseFast-built shared library.
