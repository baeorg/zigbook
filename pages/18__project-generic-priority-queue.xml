<?xml version="1.0" encoding="UTF-8"?>
<?asciidoc-toc?>
<?asciidoc-numbered?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xl="http://www.w3.org/1999/xlink" version="5.0" xml:lang="en">
<info>
<title>Project</title>
<subtitle>Generic Priority Queue</subtitle>
<date>2025-11-15</date>
</info>
<chapter xml:id="overview">
<title>Overview</title>
<simpara>Generic APIs let us describe capabilities at compile time; priority queues are where those capabilities meet the realities of time-sensitive scheduling. In this project, we wrap <literal>std.PriorityQueue</literal> with rich comparators and context-aware policies that can be tested and tuned without sacrificing zero-cost abstractions. See <link xl:href="17__generic-apis-and-type-erasure.xml">17</link> and <link xl:href="https://github.com/ziglang/zig/tree/master/lib/std/priority_queue.zig">priority_queue.zig</link>.</simpara>
<simpara>We’ll build three artefacts: a foundational dispatcher that encodes ordering rules in a comparator, a fairness simulator that reuses the same queue while changing policy context, and an analytics wrapper that tracks the top offenders in a stream. Along the way, we revisit allocator choices, weighing strategies for draining, retuning, and introspecting heaps. See <link xl:href="10__allocators-and-memory-management.xml">10</link> and <link xl:href="https://github.com/ziglang/zig/tree/master/lib/std/sort.zig">sort.zig</link>.</simpara>
</chapter>
<chapter xml:id="learning-goals">
<title>Learning Goals</title>
<itemizedlist>
<listitem>
<simpara>Translate business rules into compile-time comparator contracts that drive <literal>std.PriorityQueue</literal> ordering.</simpara>
</listitem>
<listitem>
<simpara>Model dynamic scheduling heuristics using the queue’s <literal>Context</literal> parameter while keeping memory churn predictable. <link xl:href="10__allocators-and-memory-management.xml">10</link></simpara>
</listitem>
<listitem>
<simpara>Derive streaming analytics (top-K, rolling statistics) from the same heap without copy-pasting logic or sacrificing stability. <link xl:href="45__text-formatting-and-unicode.xml">47</link></simpara>
</listitem>
</itemizedlist>
</chapter>
<chapter xml:id="architect-core">
<title>Architecting a reusable queue core</title>
<simpara>The priority queue API accepts a value type, a user-defined context, and a comparator that returns <literal>std.math.Order</literal>. That one function decides which element is bubbled to the front, so we’ll treat it as a contract backed by tests.</simpara>
<section xml:id="core-comparator-contract">
<title>Comparator design as API surface</title>
<simpara>Our first example builds a simple build-and-release dispatcher. Urgency is the primary key; submission time breaks ties so that we avoid starving older tasks. The comparator is a pure function, invoked entirely at compile time when the queue type is instantiated, yet it is expressive enough to capture nuanced ordering logic. See <link xl:href="https://github.com/ziglang/zig/tree/master/lib/std/math.zig">math.zig</link>.</simpara>
<programlisting language="zig" linenumbering="unnumbered">Unresolved directive in 18__project-generic-priority-queue.adoc - include::example$chapters-data/code/18__project-generic-priority-queue/task_queue_basics.zig[]</programlisting>
<formalpara>
<title>Run</title>
<para>
<programlisting language="shell" linenumbering="unnumbered">$ zig run task_queue_basics.zig</programlisting>
</para>
</formalpara>
<formalpara>
<title>Output</title>
<para>
<programlisting language="shell" linenumbering="unnumbered">Dispatch order:
  - compile pointer.zig (urgency 0)
  - run tests (urgency 1)
  - prepare changelog (urgency 1)
  - deploy preview (urgency 2)</programlisting>
</para>
</formalpara>
<tip>
<simpara>Because the comparator returns <literal>std.math.Order</literal>, we can layer in secondary keys without changing the queue type; the heap simply obeys the contract you encode.</simpara>
</tip>
</section>
<section xml:id="core-growth-allocation">
<title>Growth and allocation strategy</title>
<simpara>Every call to <literal>add</literal> may reallocate if the underlying slice needs more capacity. For hot paths, reserve with <literal>ensureUnusedCapacity</literal> or initialize from a pre-sized slice, then drain to amortize allocations. The queue’s <literal>deinit</literal> is cheap so long as you make allocator lifetimes explicit, mirroring the memory hygiene practices from our allocator deep dive. <link xl:href="10__allocators-and-memory-management.xml">10</link></simpara>
</section>
</chapter>
<chapter xml:id="policy-driven">
<title>Policy-driven reprioritization</title>
<simpara>Next, we feed richer data into the same queue: service requests with SLAs, time-of-day context, and VIP hints. The queue itself is agnostic; all nuance lives in the policy structure and comparator. This design keeps the heap reusable even as we layer on fairness rules. <link xl:href="17__generic-apis-and-type-erasure.xml">17</link></simpara>
<section xml:id="policy-aging">
<title>Aging and VIP weighting</title>
<simpara>The comparator computes a scalar “score” by measuring slack (time remaining until deadline), multiplying overdue requests to escalate them, and subtracting a VIP bonus. Because <literal>Context</literal> is just a struct, the policy is compiled into the queue and can be swapped by constructing a new instance with different weights. We forward-declare helper functions to keep the comparator readable and testable.</simpara>
</section>
<section xml:id="policy-scenarios">
<title>Simulating operating modes</title>
<simpara>We run two scenarios: mid-shift triage and late escalation. The only difference is the policy struct we pass to <literal>init</literal>; everything else (tasks, queue type) stays the same. The printed order shows how overdue multiplication and VIP boosts change the pop sequence.</simpara>
<programlisting language="zig" linenumbering="unnumbered">Unresolved directive in 18__project-generic-priority-queue.adoc - include::example$chapters-data/code/18__project-generic-priority-queue/sla_fairness.zig[]</programlisting>
<formalpara>
<title>Run</title>
<para>
<programlisting language="shell" linenumbering="unnumbered">$ zig run sla_fairness.zig</programlisting>
</para>
</formalpara>
<formalpara>
<title>Output</title>
<para>
<programlisting language="shell" linenumbering="unnumbered">Mid-shift triage (now=350ms)
  -&gt; INC-993 score=-20 deadline=520 vip=true
  -&gt; INC-511 score=95 deadline=400 vip=false
  -&gt; INC-742 score=140 deadline=460 vip=false
  -&gt; INC-482 score=270 deadline=500 vip=false

Escalation window (now=520ms)
  -&gt; INC-511 score=-435 deadline=400 vip=false
  -&gt; INC-742 score=-210 deadline=460 vip=false
  -&gt; INC-993 score=-40 deadline=520 vip=true
  -&gt; INC-482 score=40 deadline=500 vip=false</programlisting>
</para>
</formalpara>
<important>
<simpara>Changing policy after enqueuing existing items requires rebuilding the heap—drain into a slice, mutate the policy, then reinsert or call <literal>fromOwnedSlice</literal> to re-heapify under the new comparator. <link xl:href="10__allocators-and-memory-management.xml">10</link></simpara>
</important>
</section>
</chapter>
<chapter xml:id="analytics-topk">
<title>Analytics and top-K reporting</title>
<simpara>Priority queues are also excellent rolling aggregates. By keeping the “worst” elements in the heap and trimming aggressively, we can maintain a top-K view of latency spikes with minimal overhead. Sorting the current heap snapshot lets us render results directly for dashboards or logs. <link xl:href="45__text-formatting-and-unicode.xml">47</link></simpara>
<section xml:id="analytics-wrapper">
<title>A composable <literal>TopK</literal> wrapper</title>
<simpara><literal>TopK</literal> wraps <literal>std.PriorityQueue</literal> and uses the comparator to form a min-heap of scores. Every insert calls <literal>remove</literal> when the heap exceeds the limit, ensuring we keep only the highest scorers. The <literal>snapshotDescending</literal> helper copies the heap into a scratch buffer and sorts it with <literal>std.sort.heap</literal>, leaving the queue ready for further inserts. <link xl:href="17__generic-apis-and-type-erasure.xml">17</link></simpara>
<programlisting language="zig" linenumbering="unnumbered">Unresolved directive in 18__project-generic-priority-queue.adoc - include::example$chapters-data/code/18__project-generic-priority-queue/topk_latency.zig[]</programlisting>
<formalpara>
<title>Run</title>
<para>
<programlisting language="shell" linenumbering="unnumbered">$ zig run topk_latency.zig</programlisting>
</para>
</formalpara>
<formalpara>
<title>Output</title>
<para>
<programlisting language="shell" linenumbering="unnumbered">Top latency offenders (descending by score):
   1. /v1/ledger   latency=420ms payload=540B score=417.30
   2. /v1/ledger   latency=362ms payload=480B score=359.60
   3. /v1/payments latency=305ms payload=1500B score=297.50
   4. /v1/users    latency=275ms payload=980B score=270.10
   5. /v1/orders   latency=210ms payload=1200B score=204.00</programlisting>
</para>
</formalpara>
<note>
<simpara>Snapshotting copies the heap so that future inserts remain cheap; reuse a scratch allocator or arena for high-volume telemetry jobs to avoid fragmenting long-lived heaps. <link xl:href="10__allocators-and-memory-management.xml">10</link></simpara>
</note>
</section>
<section xml:id="closing-loop">
<title>From queues to module boundaries</title>
<simpara>We now have reusable queue wrappers that can live in their own module. The next chapter formalizes that step, showing how to surface the queue as a package-level module and expose policies through <literal>@import</literal> boundaries. <link xl:href="19__modules-and-imports-root-builtin-discovery.xml">19</link></simpara>
</section>
</chapter>
<chapter xml:id="notes-caveats">
<title>Notes &amp; Caveats</title>
<itemizedlist>
<listitem>
<simpara>Define comparators in a dedicated helper so they can be unit-tested independently and reused across queue instances. <link xl:href="13__testing-and-leak-detection.xml">13</link></simpara>
</listitem>
<listitem>
<simpara>Policy structs are value types—change detection means rebuilding the heap or creating a new queue; otherwise, your ordering no longer matches the comparator’s assumptions.</simpara>
</listitem>
<listitem>
<simpara>Copying heap contents for reporting allocates memory; recycle buffers or use arenas when integrating with telemetry services to keep GC-less Zig code predictable. <link xl:href="10__allocators-and-memory-management.xml">10</link></simpara>
</listitem>
</itemizedlist>
</chapter>
<chapter xml:id="exercises">
<title>Exercises</title>
<itemizedlist>
<listitem>
<simpara>Extend the dispatcher to respect “batch size” hints by tallying cumulative runtime in the comparator; add a test that asserts fairness across mixed priorities. <link xl:href="13__testing-and-leak-detection.xml">13</link></simpara>
</listitem>
<listitem>
<simpara>Modify the SLA simulator to write audit entries using <literal>std.log</literal> and compare the output against expectations under multiple policies. <link xl:href="https://github.com/ziglang/zig/tree/master/lib/std/log.zig">log.zig</link></simpara>
</listitem>
<listitem>
<simpara>Teach the <literal>TopK</literal> wrapper to return both the snapshot and the aggregate average; consider how you would expose that through an asynchronous metrics hook. <link xl:href="45__text-formatting-and-unicode.xml">47</link></simpara>
</listitem>
</itemizedlist>
</chapter>
<chapter xml:id="caveats-alternatives-edge-cases">
<title>Alternatives &amp; Edge Cases</title>
<itemizedlist>
<listitem>
<simpara>If you need stable ordering for items with identical scores, wrap the payload in a struct that stores a monotonically increasing sequence number and include it in the comparator.</simpara>
</listitem>
<listitem>
<simpara>For extremely large queues, consider chunking into buckets or using a pairing heap—<literal>std.PriorityQueue</literal> is binary and may incur cache misses for million-item heaps.</simpara>
</listitem>
<listitem>
<simpara>When exposing queue factories across module boundaries, document allocator ownership and provide explicit <literal>destroy</literal> helpers to prevent leaks when callers change policies at runtime. <link xl:href="19__modules-and-imports-root-builtin-discovery.xml">19</link></simpara>
</listitem>
</itemizedlist>
</chapter>
</book>