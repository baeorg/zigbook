////
changes: ["Initial profiling, optimization, and hardening chapter"]
examples_compile: yes
keywords: ["profiling", "optimization", "hardening"]
last_updated: 2025-11-06
last_verified: 2025-11-06
next_chapter: "41__cross-compilation-and-wasm"
open_questions: []
previous_chapter: "39__performance-and-inlining"
status: draft
xref_complete: true
////

= Profiling, Optimization, Hardening
:chapter-number: 40
:chapter-slug: profiling-optimization-hardening
:creative-commons:
:copyright: zigbook
:doctype: book
:embedded:
:experimental:
:icons: font
:partnums:
:pygments-linenums-mode: inline
:pygments-style: manni
:safe-mode-level: 0
:sectanchors:
:sectids:
:sectlinks:
:source-highlighter: pygments
:sourcedir: example$chapters-data/code
:webfonts:
:xrefstyle: short
:zig-version: 0.15.2
:linkcss:
:stylesdir: styles
:stylesheet: zigbook.css

[[overview]]
== Overview

Last chapter we explored semantic inlining and SIMD to shape hotspots (see xref:39__performance-and-inlining.adoc[39]); this time we go hands-on with the measurement loop that tells you whether those tweaks actually paid off. We will combine lightweight timers, build-mode comparisons, and hardened error guards to turn experimental code into a reliable toolchain. Each technique leans on recent CLI improvements, such as `zig build --time-report`, to keep feedback fast (see link:https://ziglang.org/download/0.15.1/release-notes.html#web-interface-and-time-report[v0.15.2]).

By the end of this chapter you will have a repeatable recipe: collect timing baselines, choose a release strategy (speed versus size), and run safeguards across optimization levels so regressions surface before deployment.

[[learning-goals]]
== Learning Goals

* Instrument hot paths with `std.time.Timer` and interpret the relative deltas (see link:https://github.com/ziglang/zig/tree/master/lib/std/time.zig[time.zig]).
* Compare ReleaseFast and ReleaseSmall artifacts, understanding the trade-off between diagnostics and binary size (see link:https://ziglang.org/documentation/master/#releasefast[#releasefast]).
* Harden parsing and throttling code with error guards that hold under every optimization setting (see link:https://github.com/ziglang/zig/tree/master/lib/std/testing.zig[testing.zig]).

[[profiling-with-timers]]
== Profiling Baselines with Monotonic Timers

`std.time.Timer` samples a monotonic clock, making it ideal for quick \"is it faster?\" experiments without touching global state. Paired with deterministic input data, it keeps microbenchmarks honest when you repeat them under different build modes.

[[timer-sort-bench]]
=== Example: Sorting Strategies Under a Single Timer Harness

We reuse the dataset for three algorithms—block sort, heap sort, and insertion sort—to illustrate how timing ratios guide further investigation. The dataset is regenerated for each run so cache effects stay consistent (see link:https://github.com/ziglang/zig/tree/master/lib/std/sort.zig[sort.zig]).

[source,zig]
----
include::{sourcedir}/40__profiling-optimization-hardening/01_timer_probe.zig[]
----

.Run
[source,shell]
----
$ zig run 01_timer_probe.zig -OReleaseFast
----

.Output
[source,shell]
----
optimize-mode=ReleaseFast
block sort     : 43753 ns
heap sort      : 75331 ns
insertion sort : 149541 ns
heap speedup over block: 0.58x
insertion slowdown vs block: 3.42x
----

NOTE: Follow up with `zig build --time-report -Doptimize=ReleaseFast` on the same module when you need attribution for longer stages like hashing or parsing.

[[size-strategy]]
== Trading Binary Size for Diagnostics

Switching between ReleaseFast and ReleaseSmall is more than a compiler flag: ReleaseSmall strips safety checks and aggressively prunes code to shrink the final binary. When you profile on laptops but deploy on embedded devices, build both variants and confirm the difference justifies the lost diagnostics.

[[size-comparison]]
=== Example: Tracing Logic That Disappears in ReleaseSmall

Tracing is enabled only when the optimizer leaves safety checks intact. Measuring binary sizes provides a tangible signal that ReleaseSmall is doing its job.

[source,zig]
----
include::{sourcedir}/40__profiling-optimization-hardening/02_binary_size.zig[]
----

.Run
[source,shell]
----
$ zig build-exe 02_binary_size.zig -OReleaseFast -femit-bin=perf-releasefast
$ zig build-exe 02_binary_size.zig -OReleaseSmall -femit-bin=perf-releasesmall
$ ls -lh perf-releasefast perf-releasesmall
----

.Output
[source,shell]
----
-rwxrwxr-x 1 zkevm zkevm 876K Nov  6 13:12 perf-releasefast
-rwxrwxr-x 1 zkevm zkevm  11K Nov  6 13:12 perf-releasesmall
----

TIP: Keep both artifacts around—ReleaseFast for symbol-rich profiling sessions, ReleaseSmall for production handoff. Share them via `zig build --artifact` or package manager hashes to keep CI deterministic.

[[hardening-regressions]]
== Hardening Across Optimization Modes

After tuning performance and size, wrap the pipeline with tests that assert guard rails across build modes. This is vital because ReleaseFast and ReleaseSmall disable runtime safety checks by default (see link:https://ziglang.org/documentation/master/#setruntimesafety[#setruntimesafety]). Running the same test suite in ReleaseSafe ensures diagnostics still fire when safety remains enabled.

[[guarded-pipeline]]
=== Example: Validating Input Parsing and Throttling in Every Mode

The pipeline parses limits, clamps workloads, and defends against empty input. The final test loops through values inline, mirroring the real application path while staying cheap to execute.

[source,zig]
----
include::{sourcedir}/40__profiling-optimization-hardening/03_guarded_pipeline.zig[]
----

.Run
[source,shell]
----
$ zig test 03_guarded_pipeline.zig -OReleaseFast
----

.Output
[source,shell]
----
All 4 tests passed.
----

NOTE: Repeat the command with `-OReleaseSafe` and plain `zig test` to make sure guard clauses work identically in safety-on builds. The inline loop proves the compiler can still unroll checks without sacrificing correctness.

[[notes-caveats]]
== Notes & Caveats

* Use deterministic data when microbenchmarking so timer noise reflects algorithm changes, not PRNG drift (see link:https://github.com/ziglang/zig/tree/master/lib/std/Random.zig[Random.zig]).
* ReleaseSmall disables error return traces and many assertions; pair it with a ReleaseFast smoke test before shipping to catch missing diagnostics.
* `std.debug.assert` remains active in Debug and ReleaseSafe. If ReleaseFast removes it, compensate with integration tests or explicit error handling (see link:https://github.com/ziglang/zig/tree/master/lib/std/debug.zig[debug.zig]).

[[exercises]]
== Exercises

* Add a `--sort` flag to select the algorithm at runtime, then capture `zig build --time-report` snapshots for each choice.
* Extend the size example with a `--metrics` flag that turns tracing back on; document the binary delta using `zig build-exe -fstrip` for extra savings.
* Parameterize `parseLimit` to accept hexadecimal input and tighten the tests so they run under `zig test -OReleaseSmall` without triggering UB. xref:37__illegal-behavior-and-safety-modes.adoc[37]

[[caveats-alternatives-edge-cases]]
== Alternatives & Edge Cases

* Microbenchmarks that rely on `std.debug.print` will skew ReleaseSmall timings because the call is removed. Consider logging into ring buffers instead.
* Use `zig build run --watch -fincremental` when iterating on instrumentation. Threaded codegen in 0.15.2 keeps rebuilds responsive even after large edits (see link:https://ziglang.org/download/0.15.1/release-notes.html#threaded-codegen[v0.15.2]).
* If your tests mutate data structures with undefined behavior in ReleaseFast, isolate the risky code behind `@setRuntimeSafety(true)` for the duration of the hardening exercise.
